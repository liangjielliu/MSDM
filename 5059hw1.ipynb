{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter α              F(α)                dF(α)               ddF(α)              \n",
      "0    1.0000000      -5.4556551          0.4241979           11.7582116          \n",
      "1    0.9639233      -5.4633021          -0.0002626          11.7575487          \n",
      "2    0.9639456      -5.4633021          0.0000000           11.7575774          \n",
      "收敛于 α = 0.9639456 after 3 iterations\n",
      "\n",
      "Newton’s Method 最优解: α = 0.9639456, F(α) = -5.4633021, 迭代次数: 3\n"
     ]
    }
   ],
   "source": [
    "# Part d\n",
    "import numpy as np\n",
    "\n",
    "def F(alpha):\n",
    "    return -5 * np.exp(- (alpha - 1)**2) - 3 * np.exp(-2 * (alpha + 1)**2) - 0.5 * np.sin(2 * alpha)\n",
    "\n",
    "# 计算 F'(α)\n",
    "def F_prime(alpha):\n",
    "    return 10 * (alpha - 1) * np.exp(- (alpha - 1)**2) + 12 * (alpha + 1) * np.exp(-2 * (alpha + 1)**2) - np.cos(2 * alpha)\n",
    "\n",
    "# 计算 F''(α)\n",
    "def F_double_prime(alpha):\n",
    "    return (10 * (1 - 2 * (alpha - 1)**2) * np.exp(- (alpha - 1)**2) +\n",
    "            12 * (1 - 4 * (alpha + 1)**2) * np.exp(-2 * (alpha + 1)**2) +\n",
    "            2 * np.sin(2 * alpha))\n",
    "\n",
    "# Newton’s Method 迭代\n",
    "def newton_method(alpha_init, tol=1e-6, max_iter=100):\n",
    "    alpha = alpha_init\n",
    "    print(f\"{'Iter':<5}{'α':<15}{'F(α)':<20}{'dF(α)':<20}{'ddF(α)':<20}\")\n",
    "\n",
    "    for i in range(max_iter):\n",
    "        F_p = F_prime(alpha)\n",
    "        F_pp = F_double_prime(alpha)\n",
    "\n",
    "        # 打印每次迭代的值\n",
    "        print(f\"{i:<5}{alpha:<15.7f}{F(alpha):<20.7f}{F_p:<20.7f}{F_pp:<20.7f}\")\n",
    "\n",
    "        # 如果二阶导数接近 0，避免除零错误\n",
    "        if abs(F_pp) < 1e-8:\n",
    "            print(\"二阶导数接近 0，Newton 失败\")\n",
    "            return alpha, F(alpha), i\n",
    "        \n",
    "        alpha_new = alpha - F_p / F_pp\n",
    "        \n",
    "        # 终止条件\n",
    "        if abs(alpha_new - alpha) < tol:\n",
    "            print(f\"收敛于 α = {alpha_new:.7f} after {i+1} iterations\")\n",
    "            return alpha_new, F(alpha_new), i + 1\n",
    "        \n",
    "        alpha = alpha_new\n",
    "    \n",
    "    print(\"达到最大迭代次数\")\n",
    "    return alpha, F(alpha), max_iter\n",
    "\n",
    "# 运行 Newton’s Method\n",
    "alpha_min, F_min, steps = newton_method(alpha_init=1.0)\n",
    "print(f\"\\nNewton’s Method 最优解: α = {alpha_min:.7f}, F(α) = {F_min:.7f}, 迭代次数: {steps}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter a              b              α2             F(α2)               α3             F(α3)               \n",
      "0    0.0000000      2.0000000      0.7639320      -5.2344710          1.2360680      -5.0393976          \n",
      "1    0.0000000      1.2360680      0.4721360      -4.2284254          0.7639320      -5.2344710          \n",
      "2    0.4721360      1.2360680      0.7639320      -5.2344710          0.9442719      -5.4610288          \n",
      "3    0.7639320      1.2360680      0.9442719      -5.4610288          1.0557281      -5.4138210          \n",
      "4    0.7639320      1.0557281      0.8753882      -5.4175266          0.9442719      -5.4610288          \n",
      "5    0.8753882      1.0557281      0.9442719      -5.4610288          0.9868444      -5.4602178          \n",
      "6    0.8753882      0.9868444      0.9179607      -5.4509047          0.9442719      -5.4610288          \n",
      "7    0.9179607      0.9868444      0.9442719      -5.4610288          0.9605331      -5.4632337          \n",
      "8    0.9442719      0.9868444      0.9605331      -5.4632337          0.9705831      -5.4630431          \n",
      "9    0.9442719      0.9705831      0.9543219      -5.4627579          0.9605331      -5.4632337          \n",
      "10   0.9543219      0.9705831      0.9605331      -5.4632337          0.9643719      -5.4633011          \n",
      "11   0.9605331      0.9705831      0.9643719      -5.4633011          0.9667444      -5.4632561          \n",
      "12   0.9605331      0.9667444      0.9629056      -5.4632958          0.9643719      -5.4633011          \n",
      "13   0.9629056      0.9667444      0.9643719      -5.4633011          0.9652781      -5.4632917          \n",
      "14   0.9629056      0.9652781      0.9638118      -5.4633020          0.9643719      -5.4633011          \n",
      "15   0.9629056      0.9643719      0.9634657      -5.4633008          0.9638118      -5.4633020          \n",
      "16   0.9634657      0.9643719      0.9638118      -5.4633020          0.9640258      -5.4633021          \n",
      "17   0.9638118      0.9643719      0.9640258      -5.4633021          0.9641580      -5.4633019          \n",
      "18   0.9638118      0.9641580      0.9639441      -5.4633021          0.9640258      -5.4633021          \n",
      "19   0.9638118      0.9640258      0.9638936      -5.4633021          0.9639441      -5.4633021          \n",
      "20   0.9638936      0.9640258      0.9639441      -5.4633021          0.9639753      -5.4633021          \n",
      "21   0.9638936      0.9639753      0.9639248      -5.4633021          0.9639441      -5.4633021          \n",
      "22   0.9639248      0.9639753      0.9639441      -5.4633021          0.9639560      -5.4633021          \n",
      "23   0.9639248      0.9639560      0.9639367      -5.4633021          0.9639441      -5.4633021          \n",
      "24   0.9639367      0.9639560      0.9639441      -5.4633021          0.9639486      -5.4633021          \n",
      "25   0.9639367      0.9639486      0.9639412      -5.4633021          0.9639441      -5.4633021          \n",
      "26   0.9639412      0.9639486      0.9639441      -5.4633021          0.9639458      -5.4633021          \n",
      "27   0.9639441      0.9639486      0.9639458      -5.4633021          0.9639469      -5.4633021          \n",
      "28   0.9639441      0.9639469      0.9639451      -5.4633021          0.9639458      -5.4633021          \n",
      "29   0.9639451      0.9639469      0.9639458      -5.4633021          0.9639462      -5.4633021          \n",
      "30   0.9639451      0.9639462      0.9639455      -5.4633021          0.9639458      -5.4633021          \n",
      "收敛于 α = 0.9639455 after 31 iterations\n",
      "\n",
      "黄金分割法最优解: α = 0.9639455, F(α) = -5.4633021, 迭代次数: 31\n"
     ]
    }
   ],
   "source": [
    "# Part f\n",
    "import numpy as np\n",
    "\n",
    "# 黄金分割搜索法\n",
    "def golden_section_search(a, b, tol=1e-6):\n",
    "    phi = (1 + np.sqrt(5)) / 2  # 黄金比例\n",
    "    inv_phi = 1 / phi\n",
    "\n",
    "    # 计算初始点\n",
    "    alpha2 = b - (b - a) * inv_phi\n",
    "    alpha3 = a + (b - a) * inv_phi\n",
    "    F2, F3 = F(alpha2), F(alpha3)\n",
    "\n",
    "    print(f\"{'Iter':<5}{'a':<15}{'b':<15}{'α2':<15}{'F(α2)':<20}{'α3':<15}{'F(α3)':<20}\")\n",
    "\n",
    "    for i in range(100):\n",
    "        # 打印当前迭代信息\n",
    "        print(f\"{i:<5}{a:<15.7f}{b:<15.7f}{alpha2:<15.7f}{F2:<20.7f}{alpha3:<15.7f}{F3:<20.7f}\")\n",
    "\n",
    "        if F2 < F3:\n",
    "            b, alpha3, F3 = alpha3, alpha2, F2\n",
    "            alpha2 = b - (b - a) * inv_phi\n",
    "            F2 = F(alpha2)\n",
    "        else:\n",
    "            a, alpha2, F2 = alpha2, alpha3, F3\n",
    "            alpha3 = a + (b - a) * inv_phi\n",
    "            F3 = F(alpha3)\n",
    "        \n",
    "        # 终止条件\n",
    "        if abs(b - a) < tol:\n",
    "            result_alpha = (b + a) / 2\n",
    "            result_F = F(result_alpha)\n",
    "            print(f\"收敛于 α = {result_alpha:.7f} after {i+1} iterations\")\n",
    "            return result_alpha, result_F, i + 1\n",
    "\n",
    "    print(\"达到最大迭代次数\")\n",
    "    return (b + a) / 2, F((b + a) / 2), 100\n",
    "\n",
    "# 运行黄金分割法\n",
    "alpha_min, F_min, steps = golden_section_search(0, 2)\n",
    "print(f\"\\n黄金分割法最优解: α = {alpha_min:.7f}, F(α) = {F_min:.7f}, 迭代次数: {steps}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "优化后的 x: [1.06274963 0.86457329]\n",
      "优化后的 H(x): 5.512928762654857\n"
     ]
    }
   ],
   "source": [
    "# Part g\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "def H(x1, x2):\n",
    "    \"\"\"\n",
    "    转化为最小值问题，目标函数取负号： H(x1, x2) = -[5exp(-0.5*((x1-1)^2+(x2-1)^2)) + 3exp(-((x1+1)^2+(x2+1)^2)) + sin(x1)cos(x2)]\n",
    "    \"\"\"\n",
    "    return - (5 * np.exp(-0.5 * ((x1 - 1)**2 + (x2 - 1)**2)) +\n",
    "              3 * np.exp(-((x1 + 1)**2 + (x2 + 1)**2)) +\n",
    "              np.sin(x1) * np.cos(x2))\n",
    "\n",
    "def gradient(x1, x2):\n",
    "    \"\"\"\n",
    "    计算目标函数 H 的梯度。\n",
    "    由于 H = -f，其中 f 为括号内的函数，因此梯度 H = -grad(f)。\n",
    "    \"\"\"\n",
    "    exp1 = np.exp(-0.5 * ((x1 - 1)**2 + (x2 - 1)**2))\n",
    "    exp2 = np.exp(-((x1 + 1)**2 + (x2 + 1)**2))\n",
    "    \n",
    "    dH_dx1 = 5 * (x1 - 1) * exp1 + 6 * (x1 + 1) * exp2 - np.cos(x1) * np.cos(x2)\n",
    "    dH_dx2 = 5 * (x2 - 1) * exp1 + 6 * (x2 + 1) * exp2 + np.sin(x1) * np.sin(x2)\n",
    "    \n",
    "    return np.array([dH_dx1, dH_dx2])\n",
    "\n",
    "def hessian(x1, x2):\n",
    "    \"\"\"\n",
    "    计算目标函数 H 的 Hessian 矩阵。\n",
    "    依然利用 H = -f，对 f 分别求二阶导数后取负。\n",
    "    \"\"\"\n",
    "    exp1 = np.exp(-0.5 * ((x1 - 1)**2 + (x2 - 1)**2))\n",
    "    exp2 = np.exp(-((x1 + 1)**2 + (x2 + 1)**2))\n",
    "    \n",
    "    H_x1x1_A = 5 * exp1 * (1 - (x1 - 1)**2)\n",
    "    H_x2x2_A = 5 * exp1 * (1 - (x2 - 1)**2)\n",
    "    H_x1x2_A = -5 * (x1 - 1) * (x2 - 1) * exp1\n",
    "\n",
    "    H_x1x1_B = 6 * exp2 * (2 * (x1 + 1)**2 - 1)\n",
    "    H_x2x2_B = 6 * exp2 * (2 * (x2 + 1)**2 - 1)\n",
    "    H_x1x2_B = -12 * (x1 + 1) * (x2 + 1) * exp2\n",
    "\n",
    "    H_x1x1_C = np.sin(x1) * np.cos(x2)\n",
    "    H_x2x2_C = np.sin(x1) * np.cos(x2)\n",
    "    H_x1x2_C = np.cos(x1) * np.sin(x2)\n",
    "\n",
    "    H_x1x1 = H_x1x1_A + H_x1x1_B + H_x1x1_C\n",
    "    H_x2x2 = H_x2x2_A + H_x2x2_B + H_x2x2_C\n",
    "    H_x1x2 = H_x1x2_A + H_x1x2_B + H_x1x2_C\n",
    "\n",
    "    return np.array([[H_x1x1, H_x1x2],\n",
    "                     [H_x1x2, H_x2x2]])\n",
    "\n",
    "def levenberg_marquardt(x0, tol=1e-6, max_iter=100, lambda_=0.01):\n",
    "    \"\"\"\n",
    "    Levenberg-Marquardt 算法求解最优化问题。\n",
    "    此处阻尼因子 lambda 为了简单起见保持固定。\n",
    "    \"\"\"\n",
    "    x = np.array(x0, dtype=np.float64)\n",
    "    for i in range(max_iter):\n",
    "        grad = gradient(*x)\n",
    "        hess_mat = hessian(*x)\n",
    "        I = np.eye(len(x))\n",
    "        \n",
    "        # 求解 (Hessian + lambda*I)*update = -grad\n",
    "        update = np.linalg.solve(hess_mat + lambda_ * I, -grad)\n",
    "        x_new = x + update\n",
    "        \n",
    "        if np.linalg.norm(update) < tol:\n",
    "            x = x_new\n",
    "            break\n",
    "        \n",
    "        x = x_new\n",
    "        \n",
    "    return x\n",
    "\n",
    "# 从 (1, 1) 开始搜索\n",
    "x_opt = levenberg_marquardt([1, 1])\n",
    "print(\"优化后的 x:\", x_opt)\n",
    "print(\"优化后的 H(x):\", -H(*x_opt)) # 取负值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
